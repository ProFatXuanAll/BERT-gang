r"""MNLI dataset.

Usage:
    import torch.utils.data.Dataloader
    import fine_tune

    dataset = fine_tune.task.MNLI('train')
    dataset = fine_tune.task.MNLI('dev_matched')
    dataset = fine_tune.task.MNLI('dev_mismatched')
    dataset = fine_tune.task.MNLI(...)

    dataset.update_logits(...)
    dataset.save_for_distill()

    assert fine_tune.task.get_num_label(fine_tune.task.MNLI) == 3

    assert fine_tune.task.label_encoder(
        fine_tune.task.MNLI,
        fine_tune.task.MNLI.allow_labels[0]
    ) == 0

    assert fine_tune.task.label_decoder(
        fine_tune.task.MNLI,
        0
    ) == fine_tune.task.MNLI.allow_labels[0]

    data_loader = torch.utils.data.Dataloader(
        dataset,
        collate_fn=MNLI.create_collate_fn(...)
    )
"""

# built-in modules

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import json
import logging
import os

from typing import List

# 3rd party modules

from tqdm import tqdm

# my own modules

import fine_tune.path

from fine_tune.task._dataset import (
    Dataset,
    Label,
    Sample,
    get_num_class,
    label_encoder,
)

# Get logger.

logger = logging.getLogger('fine_tune.task')

# Define MNLI dataset.


class MNLI(Dataset):
    r"""MultiNLI dataset and its utilities.

    Args:
        dataset:
            Name of MNLI dataset file to be loaded. When `dataset` is the name
            of some previous experiment, it must be MNLI logits dataset
            generated by the model of that experiment.

    Attributes:
        allow_dataset:
            Allowed MNLI dataset. See MNLI paper for more details.
        allow_labels:
            Allowed MNLI labels. We do not consider '-' label. See MNLI paper
            for labeling details.
        dataset:
            A list of MNLI samples.
        task_path:
            Path of MNLI dataset.
    """
    allow_dataset: List[str] = [
        'train',
        'dev_matched',
        'dev_mismatched',
    ]

    allow_labels: List[Label] = [
        'entailment',
        'neutral',
        'contradiction',
    ]

    task_path: str = os.path.join(
        fine_tune.path.FINE_TUNE_DATA,
        'mnli'
    )

    @staticmethod
    def load(dataset: str) -> List[Sample]:
        r"""Load MNLI dataset into memory.

        This is a heavy IO method and might required lots of memory since
        dataset might be huge. MNLI dataset must be download previously. See
        MNLI document in 'project_root/doc/fine_tune_mnli.md' for downloading
        details.

        Args:
            dataset:
                Name of the MNLI dataset to be loaded.

        Raises:
            FileNotFoundError:
                When MNLI files does not exist.

        Returns:
            A list of MNLI samples.
        """
        try:
            dataset_path = os.path.join(
                MNLI.task_path,
                f'{dataset}.jsonl'
            )
            with open(dataset_path, 'r') as jsonl_file:
                jsonlines = jsonl_file.readlines()
        except FileNotFoundError:
            raise FileNotFoundError(
                f'MNLI dataset file {dataset} does not exist.\n' +
                'You must downloaded previously and put it in the path:\n' +
                f'{dataset_path}\n' +
                "See '" +
                os.path.join(fine_tune.path.DOC, 'fine_tune_mnli.md') +
                "' for downloading details."
            )

        samples = []
        skipped_sample_count = 0
        for line in tqdm(jsonlines, desc=f'Loading MNLI {dataset}'):
            # Skip empty line.
            if line == '':
                continue

            sample = json.loads(line)

            # Skip sample which label is '-'. See MNLI paper for labeling
            # details.
            if sample['gold_label'] == '-':
                skipped_sample_count += 1
                continue

            # Format into `transformer.PreTrainedTokenizer` format. MNLI labels
            # will be encoded with `label_encoder(MNLI, label)`. `logits`
            # will be initialized with 3 zeros.
            samples.append(
                Sample({
                    'text': sample['sentence1'],
                    'text_pair': sample['sentence2'],
                    'label': label_encoder(MNLI, sample['gold_label']),
                    'logits': [0.0] * get_num_class(MNLI),
                })
            )

        logger.info(
            'Number of origin samples: %d',
            len(samples) + skipped_sample_count
        )
        logger.info('Number of skiped samples: %d', skipped_sample_count)
        logger.info('Number of result samples: %d', len(samples))

        return samples

    @staticmethod
    def load_distill(experiment_name: str) -> List[Sample]:
        r"""Load MNLI distillation dataset into memory.

        This is a heavy IO method and might required lots of memory since
        dataset might be huge. MNLI distillation dataset must be generated by
        some previous experiment. See MNLI document in
        'project_root/doc/fine_tune_mnli.md' for generating distillation
        dataset details.

        Args:
            experiment_name:
                Name of the MNLI fine-tune experiment generated by
                `fine_tune.config.BaseConfig.experiment_name()`.

        Raises:
            FileNotFoundError:
                When MNLI distillation dataset file does not exist.

        Returns:
            A list of samples of MNLI distillation dataset.
        """

        try:
            dataset_path = os.path.join(
                fine_tune.path.FINE_TUNE_EXPERIMENT,
                experiment_name,
                'mnli-distill.jsonl'
            )
            with open(dataset_path, 'r') as jsonl_file:
                jsonlines = jsonl_file.readlines()
        except FileNotFoundError:
            raise FileNotFoundError(
                f'MNLI distillation experiment {experiment_name} does not ' +
                'exist.\nYou must generate distillation dataset previously ' +
                'and put it in the path:\n' +
                f'{dataset_path}\n' +
                "See '" +
                os.path.join(fine_tune.path.DOC, 'fine_tune_mnli.md') +
                "' for generating distillation dataset details."
            )

        samples = []
        for line in tqdm(
                jsonlines,
                desc=f'Loading MNLI distillation experiment {experiment_name}'
        ):
            # Skip empty line.
            if line == '':
                continue

            samples.append(Sample(json.loads(line)))

        logger.info('Number of distill samples: %d', len(samples))

        return samples

    def save_for_distill(
            self,
            experiment_name: str
    ):
        r"""Save logits for MNLI distillation.

        Args:
            experiment_name:
                Name of the MNLI fine-tune experiment generated by
                `fine_tune.config.BaseConfig.experiment_name()`.
        """
        dataset_dir = os.path.join(
            fine_tune.path.FINE_TUNE_EXPERIMENT,
            experiment_name
        )
        dataset_path = os.path.join(
            dataset_dir,
            'mnli-distill.jsonl'
        )

        if not os.path.exists(dataset_dir):
            os.makedirs(dataset_dir)

        with open(dataset_path, 'w', encoding='utf-8') as jsonl_file:
            for index in range(len(self.dataset)):
                sample = json.dumps(self.dataset[index], ensure_ascii=False)
                jsonl_file.write(f'{sample}\n')
