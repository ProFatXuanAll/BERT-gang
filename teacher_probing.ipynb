{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitbertgangpipenv77b04f50b17c47449fab907831a34141",
   "display_name": "Python 3.8.0  ('.venv': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "aac980e9d45c77b293844917a2b86523f8503b71441fd482be0b9870555abfa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Techer model probing: Performance after remove some teacher layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fine_tune\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'qnli'\n",
    "TEACHER_EXP = 'teacher_base'\n",
    "TMODEL = 'bert'\n",
    "TCKPT = 8000\n",
    "DATASET = 'dev'\n",
    "HIDDEN_LAYERS = 6\n",
    "SDEVICE = 1\n",
    "TDEVICE = 1\n",
    "BATCH_SIZE = 32\n",
    "LAYER_MAPPING = 'odd'\n",
    "\n",
    "if TASK == 'qnli':\n",
    "    NUM_CLASS = 2\n",
    "elif TASK == 'mnli':\n",
    "    NUM_CLASS = 3\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported task {task}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kychen/Desktop/BERT-gang/data/fine_tune_experiment/teacher_base_bert_mnli/config.json'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6aba64f2e088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m teacher_config = fine_tune.config.TeacherConfig.load(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEACHER_EXP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/BERT-gang/fine_tune/config/_base_config.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, experiment, model, task)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         )\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kychen/Desktop/BERT-gang/data/fine_tune_experiment/teacher_base_bert_mnli/config.json'"
     ]
    }
   ],
   "source": [
    "teacher_config = fine_tune.config.TeacherConfig.load(\n",
    "    experiment=TEACHER_EXP,\n",
    "    model=TMODEL,\n",
    "    task=TASK\n",
    ")\n",
    "teacher_config.device_id = TDEVICE\n",
    "teacher_config.dataset = DATASET\n",
    "print(teacher_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune.util.set_seed_by_config(teacher_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/06/01 17:29:12 - INFO - fine_tune.task -   Start loading task QNLI dataset dev.\n",
      "Loading QNLI dev: 5463it [00:00, 411247.60it/s]\n",
      "2021/06/01 17:29:12 - INFO - fine_tune.task -   Number of samples: 5463\n",
      "2021/06/01 17:29:12 - INFO - fine_tune.task -   Finish loading task QNLI dataset dev.\n"
     ]
    }
   ],
   "source": [
    "dataset = fine_tune.util.load_dataset_by_config(\n",
    "    config=teacher_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_config = fine_tune.config.StudentConfig(\n",
    "    accum_step = 1,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    d_emb = 128,\n",
    "    d_ff = 3072,\n",
    "    d_model = 768,\n",
    "    dataset = teacher_config.dataset,\n",
    "    experiment = 'QNLI_TEACHER_PROBING',\n",
    "    dropout = 0.1,\n",
    "    eps = 1e-8,\n",
    "    log_step = 100,\n",
    "    lr = 3e-5,\n",
    "    max_norm = 1.0,\n",
    "    num_attention_heads = 12,\n",
    "    num_hidden_layers = HIDDEN_LAYERS,\n",
    "    seed = teacher_config.seed,\n",
    "    max_seq_len = 128,\n",
    "    model = 'bert',\n",
    "    num_class = NUM_CLASS,\n",
    "    task = TASK,\n",
    "    total_step = 13096,\n",
    "    type_vocab_size = 2,\n",
    "    warmup_step = 1309,\n",
    "    weight_decay = 0.01,\n",
    "    device_id = SDEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n+---------------------------------------------+\n| configuration        | value                |\n+---------------------------------------------+\n| accum_step           | 1                    |\n| amp                  | 0                    |\n| batch_size           | 32                   |\n| beta1                | 0.9                  |\n| beta2                | 0.999                |\n| ckpt_step            | 1000                 |\n| d_emb                | 128                  |\n| d_ff                 | 3072                 |\n| d_model              | 768                  |\n| dataset              | dev                  |\n| device_id            | 1                    |\n| dropout              | 0.1                  |\n| eps                  | 1e-08                |\n| experiment           | QNLI_TEACHER_PROBING |\n| log_step             | 100                  |\n| lr                   | 3e-05                |\n| max_norm             | 1.0                  |\n| max_seq_len          | 128                  |\n| model                | bert                 |\n| num_attention_heads  | 12                   |\n| num_class            | 2                    |\n| num_hidden_layers    | 6                    |\n| seed                 | 42                   |\n| task                 | qnli                 |\n| total_step           | 13096                |\n| type_vocab_size      | 2                    |\n| warmup_step          | 1309                 |\n| weight_decay         | 0.01                 |\n+---------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(student_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tknr = fine_tune.util.load_teacher_tokenizer_by_config(\n",
    "    config=teacher_config\n",
    ")\n",
    "student_tknr = fine_tune.util.load_student_tokenizer_by_config(\n",
    "    config=student_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/kychen/Desktop/BERT-gang/data/fine_tune_experiment/teacher_base_bert_qnli\n"
     ]
    }
   ],
   "source": [
    "TEACHER_EXP_NAME = fine_tune.config.BaseConfig.experiment_name(\n",
    "    experiment=teacher_config.experiment,\n",
    "    model=teacher_config.model,\n",
    "    task=teacher_config.task\n",
    ")\n",
    "TEACHER_EXP_DIR = os.path.join(\n",
    "    fine_tune.path.FINE_TUNE_EXPERIMENT,\n",
    "    TEACHER_EXP_NAME\n",
    ")\n",
    "print(TEACHER_EXP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "teacher_model = fine_tune.util.load_teacher_model_by_config(\n",
    "    config=teacher_config\n",
    ")\n",
    "teacher_model.load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(TEACHER_EXP_DIR, f'model-{TCKPT}.pt'),\n",
    "        map_location=teacher_config.device\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = fine_tune.util.load_student_model_by_config(\n",
    "    config=student_config,\n",
    "    tokenizer=student_tknr\n",
    ")"
   ]
  },
  {
   "source": [
    "# Load fine-tuned teacher weight"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LAYER_MAPPING == 'even':\n",
    "    teacher_indices = list(range(1, 12, 2))\n",
    "elif LAYER_MAPPING == 'odd':\n",
    "    teacher_indices = list(range(0, 12, 2))\n",
    "elif LAYER_MAPPING == 'user_defined':\n",
    "    teacher_indices = [int(item)-1 for item in input(\"Enter desired teacher layer:\\n\").split()]\n",
    "else:\n",
    "    raise ValueError(f\"Invalid mapping strategy: {LAYER_MAPPING}\")"
   ]
  },
  {
   "source": [
    "## Load Encoder weight"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_encoder_weight = teacher_model.encoder.state_dict()\n",
    "new_state_dict = {}\n",
    "keys = [\n",
    "    'attention.self.query.weight',\n",
    "    'attention.self.query.bias',\n",
    "    'attention.self.key.weight',\n",
    "    'attention.self.key.bias',\n",
    "    'attention.self.value.weight',\n",
    "    'attention.self.value.bias',\n",
    "    'attention.output.dense.weight',\n",
    "    'attention.output.dense.bias',\n",
    "    'attention.output.LayerNorm.weight',\n",
    "    'attention.output.LayerNorm.bias',\n",
    "    'intermediate.dense.weight',\n",
    "    'intermediate.dense.bias',\n",
    "    'output.dense.weight',\n",
    "    'output.dense.bias',\n",
    "    'output.LayerNorm.weight',\n",
    "    'output.LayerNorm.bias'\n",
    "]\n",
    "\n",
    "for i, t_index in enumerate(teacher_indices):\n",
    "    for key in keys:\n",
    "        new_state_dict.update(\n",
    "            {\n",
    "                f'encoder.layer.{i}.{key}':\n",
    "                teacher_encoder_weight[f'encoder.layer.{t_index}.{key}']\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict.update(\n",
    "    {\n",
    "        'pooler.dense.weight':teacher_encoder_weight['pooler.dense.weight'],\n",
    "        'pooler.dense.bias':teacher_encoder_weight['pooler.dense.bias']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['embeddings.position_ids', 'embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias'], unexpected_keys=[])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "student_model.encoder.load_state_dict(\n",
    "    new_state_dict,\n",
    "    strict=False\n",
    ")"
   ]
  },
  {
   "source": [
    "## Load classification layer weight"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "teacher_linear_weight = teacher_model.linear_layer.state_dict()\n",
    "student_model.linear_layer.load_state_dict(\n",
    "    teacher_linear_weight\n",
    ")"
   ]
  },
  {
   "source": [
    "# Run Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 171/171 [00:11<00:00, 14.49it/s]\n"
     ]
    }
   ],
   "source": [
    "acc = fine_tune.util.evaluation(\n",
    "    config=student_config,\n",
    "    dataset=dataset,\n",
    "    model=student_model,\n",
    "    tokenizer=student_tknr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5053999633900788\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}